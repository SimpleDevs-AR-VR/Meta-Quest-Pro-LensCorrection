# Meta Quest Pro Lens Correction

_A miniature project to find a way to correct the artificial lens distortion generated by the Meta Quest Pro when recording using `scrcpy` and `ffmpeg`._

This project assumes you have collected raw screen footage from a Meta Quest Pro or other Android-based head-mounted display (HMD) virtual/augmented reality headset. If not, we have a toolkit offered [here for the Meta Quest Pro](git@github.com:SimpleDevs-AR-VR/Meta-Quest-Pro-SCRCPY.git).

[![Watch the video](./docs/captured_footage.png)](https://youtu.be/zhfMPfGJFuc)

## Correcting for Distortion

We have two separate footage streams condensed into one single video, complete with artificial distortion.

![Raw SCRCPY Capture](./docs/raw_scrcpy_capture.png)

We want to attempt to correct for this artificial distortion so that we can begin to derive good footage of our AR/VR application in action. We can attempt to perform a kind of lens correction using FFMPEG. Similar to **scrcpy**, **ffmpeg** is a command-line tool that allows users to modify images, videos, audio, and other media-related content. Luckily, **ffmpeg** comes with a command to correct for lens distortion: literally `lenscorrection=k1=<FLOAT>:k2=<FLOAT>`. Let's use this to our advantage.

In addition, it's perhaps more optimal to attempt to look at only a singular eye rather than both eyes. Both eye perspectives are likely to contain similar visual information, and thus it will be simpler to crop the footage to focus on one eye prior to lens correction.

Finally, because the footage is angled at a particular degree from the horizon (approximately 18 degrees), we need to fix that as well.

## Commands and Parameters

If you've used [our method for eye footage capture using **scrcpy**](git@github.com:SimpleDevs-AR-VR/Meta-Quest-Pro-SCRCPY.git), you were provided two options to capture the footage: 

* `-m1080` : 1080 x 568
* `-m1280` : 1280 x 672

Of course, you are completely free to use whichever aspect ratio when recording via **scrcpy**. However, we'll focus on these two specific formats.

The full command to perform lens correction is (for the left eye):

### `-m1080`

````
ffmpeg <file_location>.mp4 -vf "crop=530:568:15:0,lenscorrection=k1=0.3:k2=-0.55,rotate=18*(PI/180)" -vsync 2 <output_file>.mp4
````

### `-m1280`

````
ffmpeg <file_location>.mp4 -vf "crop=628:672:18:0,lenscorrection=k1=0.3:k2=-0.55,rotate=18*(PI/180)" -vsync 2 <output_file>.mp4
````

**NOTE:** Please ensure that you have `-vsync 2` included as an argument passed to the **ffmpeg** command, as this ensures that all video processing occurs quickly.

### Example Process

1. Capture the raw footage using SCRCPY.
![Raw Capture](./docs/results_1.png)
_Original Raw Footage_

2. Isolate the image to a single eye view.
![Cropped, Distorted](./docs/results_2.png)
_Cropped, Distorted_

3. Reverse the artificial lens distortion to "straighten" the image or video.
![Cropped, Corrected](./docs/results_3.png)
_Cropped, Corrected_

## Lens Correction Mathematics + Parameters

The algorithm for lens correction:

$$
r_{src} = r_{tgt}\left( 1 + k_1\left( \frac{r_{tgt}}{r_0} \right)^2 + k_2 \left( \frac{r_{tgt}}{r_0} \right)^4 \right)
$$

Where:

* $r_{src}$ = the distance to the focal point in the **target** image
* $r_{tgt}$ = distance to focal point in the **source** image
* $r_0$ = half of the image diagonal
* $k_1, k_2$ = hyperparameters for correction

This is implemented through `ffmpeg`â€™s `lenscorrection` filter, which accepts a `cx`, `cy`, `k1`, and `k2` as hyperparameters.

The two parameters `k1` and `k2` were determined based on visual observation and comparison of results derived using `EstimateDistortion.py`, which is provided alongside this repository. The optimal parameters based on this comparison are:

* `k2`: `0.3`
* `k1`: `-0.55`

## Crop Parameters

These were determined based on visual observation of the captured footage. The raw cropping parameters are provided below:

### -m1080

````bash
ffmpeg -i <INPUT_VIDEO_PATH> -vf "crop=530:568:15:0" -vsync 2 <OUTPUT_VIDEO_PATH>
````

where:

* `out_w`: The width of the cropped area: `530`
* `out_h`: The height of the cropped area: `568`
* `x`: The x-coordinate of the topleft corner of the cropped area: `15`
* `y`: The y-coordinate of the topleft corner of the cropped area: `0`

### -m1280

````bash
ffmpeg -i <INPUT_VIDEO_PATH> -vf "crop=628:672:18:0" -vsync 2 <OUTPUT_VIDEO_PATH>
````

where:

* `out_w`: The width of the cropped area: `628`
* `out_h`: The height of the cropped area: `672`
* `x`: The x-coordinate of the topleft corner of the cropped area: `18`
* `y`: The y-coordinate of the topleft corner of the cropped area: `0`

## Notes on Executable Python Scripts

This repository comes with two script files:

* `EstimateDistortion.py`
* `GetScreenshotFromVideo.py`

The 2nd file is purely for debugging. The key star of the show is the 1st file, `EstimateDistortion.py`. This script, when called, produces multiple possible parameters for `k1` and `k2` and visualizes the results for us.

To call this script, simply execute:

````bash
python EstimateDistortion.py
````

**Please be aware of the following**:

* You must have an empty `inputs`, `processing`, and `output` directories located in the same local directory as the script. The script will not work without these folders present.
* The script, when called, produces multiple possible combinations of `k1` and `k2`. It's YOUR job to look through these and determine what's the best possible combination.
* The total runtime is intense. Make sure you have something you can do in the meantime. Total runtime can range between 10 to 20 minutes.
* This step of the process can be performed in post, meaning you don't need to run this script on the Rasberry Pi 4. You can easily just use the Rasberry Pi 4 for the video recording, then run this part of the pipeline on your more-powerful PC setup.